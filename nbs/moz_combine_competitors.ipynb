{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b53f77-8ad1-4d58-8cdf-18ebad8422bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce02ae-f739-4e4e-9247-0b50c94302d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp moz_combine_competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178bb4e-ed7f-4b13-8185-3fd2724bfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "\n",
    "dfs = []\n",
    "our_sites = []\n",
    "for f in Path(DATA_DIR).glob(\"Competitive Research_ True Competitor - Moz Pro*.csv\"):\n",
    "    fname = f.name\n",
    "    site = fname.split()[-1][4:-4]\n",
    "    our_sites.append(site)\n",
    "    df = pd.read_csv(f, encoding=\"utf-8\")\n",
    "    df[\"Competitor\"] = site\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# Convert the percentage column to a float\n",
    "df[\"Overlap\"] = df[\"Overlap\"].str.strip().str.rstrip(\"%\").astype(float) / 100\n",
    "\n",
    "# Filter to sites that have at least 2% keyword overlap\n",
    "df = df[df[\"Overlap\"] > 0.02]\n",
    "\n",
    "# Sort by where there's the most overlap\n",
    "df.sort_values(\"Overlap\", ascending=False, inplace=True)\n",
    "\n",
    "competitors = set(df[\"Top Competitor URLs\"].unique())\n",
    "\n",
    "\n",
    "def get_final_redirect(apex_domain):\n",
    "    url = f\"https://{apex_domain}\"\n",
    "    try:\n",
    "        response = requests.head(url, allow_redirects=True)\n",
    "        return response.url\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def chop_protocol(url):\n",
    "    \"\"\"\n",
    "    Takes a URL as input and chops off either the secure or non-secure protocol\n",
    "    from the beginning of the URL, returning the result.\n",
    "    \"\"\"\n",
    "    # Define the protocols we want to remove\n",
    "    protocols = [\"http://\", \"https://\"]\n",
    "\n",
    "    # Loop through each protocol and remove it if it exists\n",
    "    for protocol in protocols:\n",
    "        if url.startswith(protocol):\n",
    "            url = url[len(protocol) :]\n",
    "            if url[-1] == \"/\":\n",
    "                url = url[:-1]\n",
    "            break\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "our_resolved_sites = set()\n",
    "for site in our_sites:\n",
    "    landing_page = get_final_redirect(site)\n",
    "    chopped_protocol = chop_protocol(landing_page)\n",
    "    our_resolved_sites.add(chopped_protocol)\n",
    "\n",
    "# Show original list lengths\n",
    "print(f\"Seed Sites: {len(our_resolved_sites)}\")\n",
    "print(f\"Competitors: {len(competitors)}\")\n",
    "\n",
    "# Show the combined lists\n",
    "all_sites = competitors | our_resolved_sites\n",
    "print(f\"Combined before fitlering: {len(all_sites)}\")\n",
    "\n",
    "# Show the combined lists after we removed blacklisted sites\n",
    "pull_sites = all_sites - black_list\n",
    "print(f\"Combined after fitlering: {len(pull_sites)}\")\n",
    "\n",
    "# Save the file in the data directory\n",
    "save_as = DATA_DIR + \"pull_keywords.txt\"\n",
    "with open(save_as, \"w\") as fh:\n",
    "    for site in pull_sites:\n",
    "        fh.write(site + \"\\n\")\n",
    "print(f\"{save_as} saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2f56e-7bde-4293-aeff-46a61f68f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb907e7c-a6b5-4d91-86a2-33c079327254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e7602-dfc7-4ae1-863a-09b9137cc274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
