{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13632f9-bbc7-4663-a12d-ded95a757f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00068c7d-ec7a-4ebd-bc24-5311b2b16bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp moz_pull_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d0aa5-1bae-42ae-85b9-edc503e72951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import re\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from playwright.async_api import Playwright, async_playwright\n",
    "\n",
    "\n",
    "PAUSE_TO_RECORD = False\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "load_from = DATA_DIR + \"pull_keywords.txt\"\n",
    "\n",
    "slow_mo = 100\n",
    "moz_creds = \"/home/ubuntu/repos/moz/assets/mozcreds.txt\"\n",
    "chrome_exe = \"/usr/bin/google-chrome\"\n",
    "downloads_path = \"/home/ubuntu/Downloads\"\n",
    "user_data = \"/home/ubuntu/.config/google-chrome/\"\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    \"\"\"Return True if run from a Jupyter Notebook and False if not.\"\"\"\n",
    "    try:\n",
    "        import IPython\n",
    "\n",
    "        if IPython.get_ipython().__class__.__name__ == \"ZMQInteractiveShell\":\n",
    "            return True  # Jupyter notebook or qtconsole\n",
    "        else:\n",
    "            return False  # Other type (likely a script)\n",
    "    except NameError:\n",
    "        return False  # Probably standard Python interpreter\n",
    "\n",
    "\n",
    "if in_notebook():\n",
    "    keyword = \"example.com\"  # or set to any default value that you prefer\n",
    "    headless = False\n",
    "else:\n",
    "    import argparse\n",
    "\n",
    "    headless = True\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Pull keywords from MOZ Pro given -s site.\"\n",
    "    )\n",
    "    parser.add_argument(\"-s\", \"--site\", type=str, required=True, help=\"Value for site\")\n",
    "    args = parser.parse_args()\n",
    "    keyword = args.keyword\n",
    "\n",
    "with open(moz_creds) as fh:\n",
    "    UN, PW = [x.strip().split(\" \")[1] for x in fh.readlines()]\n",
    "\n",
    "async def main():\n",
    "    for attempt in range(10):\n",
    "        if len(list(Path(\"/home/ubuntu/repos/moz/downloads/\").glob(\"*.csv\"))) == len(list(Path(\"/home/ubuntu/repos/moz/downloads/\").glob(\"*.csv\"))):\n",
    "            print(\"Done\")\n",
    "            raise SystemExit()\n",
    "        try:\n",
    "            async with async_playwright() as playwright:\n",
    "                context = await playwright.chromium.launch_persistent_context(\n",
    "                    viewport={\"width\": 1600, \"height\": 900},\n",
    "                    downloads_path=downloads_path,\n",
    "                    executable_path=chrome_exe,\n",
    "                    user_data_dir=user_data,\n",
    "                    accept_downloads=True,\n",
    "                    headless=headless,\n",
    "                    channel=\"chrome\",\n",
    "                    slow_mo=slow_mo,\n",
    "                )\n",
    "                page = await context.new_page()\n",
    "                await page.goto(\"https://moz.com/\")\n",
    "\n",
    "                try:\n",
    "                    await page.get_by_role(\"link\", name=\"Log in\").click()\n",
    "                    await page.locator(\"#email\").click()\n",
    "                    await page.locator(\"#email\").fill(UN)\n",
    "                    await page.locator(\"#email\").press(\"Tab\")\n",
    "                    await page.locator(\"#password\").fill(PW)\n",
    "                    await page.locator(\"#password\").press(\"Enter\")\n",
    "                except:\n",
    "                    ...\n",
    "\n",
    "                # Codegen activated\n",
    "                if PAUSE_TO_RECORD:\n",
    "                    await page.pause()  # Edit this line in for codegen and out for automation.\n",
    "\n",
    "                # -- BEGIN CODEGEN LINES --\n",
    "\n",
    "                await page.get_by_title(\"Moz Pro\").click()\n",
    "                await page.get_by_role(\"link\", name=\"Moz Pro Home\").click()\n",
    "                await page.get_by_role(\"link\", name=\"Keyword Research\").click()\n",
    "                with open(load_from) as fh:\n",
    "                    for i, line in enumerate(fh.readlines()):\n",
    "                        site = line.strip()  \n",
    "                        # Build a set of everything already downloaded\n",
    "                        seen = set()\n",
    "                        for file in Path(\"/home/ubuntu/repos/moz/downloads/\").glob(\"*.csv\"):\n",
    "                            seen_site = file.name.split(\"_\")[1]\n",
    "                            seen.add(seen_site)\n",
    "                        if site not in seen:\n",
    "                            print(i, site)\n",
    "                            await page.get_by_role(\"link\", name=\"Ranking Keywords\").click()\n",
    "                            await asyncio.sleep(3)\n",
    "                            await page.locator(\"form\").filter(has_text=\"root domainUnited States - en-USanalyze\").locator(\"span\").first.click()\n",
    "                            await page.get_by_role(\"listitem\").filter(has_text=\"subdomain\").click()\n",
    "                            await page.get_by_placeholder(\"Enter a subdomain (ex: news.mydomain.com) to find keywords that rank\").click()\n",
    "                            await page.get_by_placeholder(\"Enter a subdomain (ex: news.mydomain.com) to find keywords that rank\").fill(site)\n",
    "                            await page.get_by_role(\"button\", name=\"analyze\").click()\n",
    "                            async with page.expect_download(timeout=5000000) as download_info:\n",
    "                                await page.get_by_role(\"button\", name=\"Export CSV\").click()\n",
    "                            download = await download_info.value\n",
    "                            download = download_info.value                    \n",
    "                            download = await download\n",
    "                            await download.save_as(\n",
    "                                \"/home/ubuntu/repos/moz/downloads/\" + download.suggested_filename\n",
    "                            )\n",
    "                # When done, close the browser.\n",
    "                await asyncio.sleep(10)\n",
    "                await context.close()\n",
    "        except:\n",
    "            await asyncio.sleep(10)\n",
    "            ...\n",
    "\n",
    "\n",
    "async def run_main():\n",
    "    await main()\n",
    "\n",
    "\n",
    "if in_notebook():\n",
    "    try:\n",
    "        asyncio.get_running_loop()\n",
    "        asyncio.run(run_main())\n",
    "    except RuntimeError as e:\n",
    "        if \"no running event loop\" in str(e):\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            loop.run_until_complete(run_main())\n",
    "else:\n",
    "    asyncio.run(run_main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c8aa9-766f-44fd-b8b8-6e627d242269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
