{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0718765-b219-4cbc-a151-3c11f4d00d57",
   "metadata": {},
   "source": [
    "# Let's get started\n",
    "\n",
    "## Pickling Cats\n",
    "\n",
    "In this tutorial, we will pickle some cats. We will only need to pickle the cat's keys, because the main source of cat pics will remain unmoved where they first sat down for a nap &#151; that is to say, in ***cats/source***. All this tutorial's work will be in ***cats/thumbs***. I've chosen to hardwire \"thumbs\", but have kept cats flexible. If you need project namespaces I suggest changing cats to dogs or something else more suitable.\n",
    "\n",
    "### Lab_Black\n",
    "\n",
    "First, good habits. Running `%load_ext lab_black` makes all your code format to uncompromoisingly compliant with some such-and-such. But it's pretty and works, so I use it. Most comments from here forward are Python comments in the code-blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22536e76-d050-4b05-936e-739afd6cac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5f834-a7c8-426a-a891-0293b5a7069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I load a few extrnal libraries here.\n",
    "# Examples run on a Linux JupyterLab per https://mikelev.in/ux\n",
    "# We don't need much at first. I'll do more of these later.\n",
    "# Package import statements like these load resources taht are\n",
    "# not loaded by default. Some have already been pip installed.\n",
    "# Go ahead and run this cell.\n",
    "\n",
    "from time import time  # To measure how many seconds things took\n",
    "from pathlib import Path  # To read & write to the local drive\n",
    "import matplotlib.pyplot as plt  # To display data (graphs)\n",
    "from pickle import loads, dumps  # Load/save Python data to drive.\n",
    "from sqlitedict import SqliteDict as sqldict  # Treat dicts as dbs.\n",
    "\n",
    "print(\"Very good. Now you can run the next cell.\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8eb690-61ad-4805-8dc7-de075a7a87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The global data variable becomes your file read/write namespace.\n",
    "# Choose something you want as a directory, folder, git repo name.\n",
    "# You can work in any folder and this will still organize your data.\n",
    "# Watch for a folder appearing next to this Notebook called \"cats\"...\n",
    "# (If cats already exists, it skips this step)\n",
    "\n",
    "data = \"cats\"\n",
    "Path(data).mkdir(exist_ok=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc10a0-fcb3-49fa-8f53-66212b20e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count from 0 to 9 in Python.\n",
    "# Notice how we change the \"end of line\" behavior of print.\n",
    "for i in range(10):\n",
    "    print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f34bb2-f096-4539-a27b-ed46fb59641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get visual right away. It's so easy in Jupyter, why not?\n",
    "# Let's plot from 0 to 9 in matplotlib. Both X and Y contain 0 to 9.\n",
    "\n",
    "plt.title(\"When X = Y\")\n",
    "plt.xlabel(\"range(10)\")\n",
    "plt.ylabel(\"range(10)\")\n",
    "plt.plot(range(10), range(10))\n",
    "plt.show()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87161f32-802e-4733-8e41-16b28d4cfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count from 1 to 10 in .\n",
    "# It's worth knowing that you CAN start counting from 1.\n",
    "\n",
    "for i in range(1, 11):\n",
    "    print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28e486-d531-4c4d-8478-cf18a675b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Though you can make it 1 when yu need it, doesn't it just look\n",
    "# so much nicer like this? Don't make it harder than you need to.\n",
    "\n",
    "for i in range(10):\n",
    "    print(i + 1, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a3baf-3146-4057-8eea-9599d962695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are so many cases where you have to do something every X-rows\n",
    "# we look at that first. Notice the Modulo operator. On every 1000 rows\n",
    "# the calculation returns 0 so that if-line evaluates true. It's a good\n",
    "# way to make count-down timers that don't over-print to your Notebook.\n",
    "\n",
    "for i in range(100000):\n",
    "    if not i % 1000:\n",
    "        print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83b3a2-576c-4695-b34b-7e731be8607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are now in Wonderland. Everything in math you thought too abstract\n",
    "# to do you any good in real-life now does you good. Let's use powers of 10\n",
    "# to restate the above. See? Isn't it nice to just know how many 0's?\n",
    "\n",
    "for i in range(10**5):  # Ten with 5 0's is 100,000.\n",
    "    if not i % 10**3:  # Ten with 3 0's is 1,000.\n",
    "        print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d91e8a-5380-4a21-b512-7e6736ff8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers are most easily read when formatted well for reading.\n",
    "# We will be making heavy use of \"f-strings\". Notice the colon-comma:\n",
    "\n",
    "for i in range(10**5):\n",
    "    if not i % 10**3:\n",
    "        print(f\"{i:,}\", end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0ac8a-a215-4fb8-bb77-8454078c4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're working on formatting, you ought to know you have a\n",
    "# rich environment for outputting structures like tables.\n",
    "# While you're at it, get used to seing tuples get splat.\n",
    "# The table-formatter is Rich. I don't use it much, but\n",
    "# you do almost every time you pip install.\n",
    "\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(show_header=True, header_style=\"bold red\")\n",
    "table.add_column(\"thou_step\", style=\"green\", width=12)\n",
    "table.add_column(\"foo\", style=\"cyan\", width=12)\n",
    "\n",
    "for i in range(10**5):\n",
    "    if not i % 10**3:\n",
    "        atuple = (f\"{i:,}\", \"bar\")\n",
    "        table.add_row(*atuple)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b022d-c126-404b-94dd-3c2d8e270545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more popular way to view your data is as \"Pandas DataFrames\".\n",
    "# These are in-memory Excel tabs or SQL tables, if you will.\n",
    "# They're not really databases, but are often used as such.\n",
    "# We will make one here from this loop. We stop f-string comma formatting\n",
    "# because as a pd df, we can do it Pythonically pedantically idiomatically.\n",
    "# I use his approach all the time.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "table = []\n",
    "for i in range(10**5):\n",
    "    if not i % 10**3:\n",
    "        table.append(i)\n",
    "df = pd.DataFrame(table, columns=[\"thousands\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf762e-4c90-41af-980a-37ab103fc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data-types of that DataFrame.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01c729-1967-42da-ba6c-3644398cbea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To format a number with commas, we make it a float.\n",
    "# It now displays commas in floats used in Pandas in this Notebook\n",
    "# But when you save or convert the data, the commas are not used.\n",
    "# Pandas DataFrames are great for Excel or SQL-like things in Python\n",
    "# except without having to have a database. You load and save files.\n",
    "\n",
    "pd.options.display.float_format = \"{:,}\".format\n",
    "\n",
    "df = df.astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5e3a9-33b3-4ea4-87c1-0d894702ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This df can be saved to your drive as data in various ways.\n",
    "# Here we will use one of the best alternatives to CSV for large files.\n",
    "\n",
    "df.to_parquet(f\"{data}/notbutter.parquet\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ace7e-9c42-457d-af72-7600207d032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And you can load it back off of the drive.\n",
    "# Yes, I'm recycling the same variable names, but trust me.\n",
    "\n",
    "df = pd.read_parquet(f\"{data}/notbutter.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df744e-db78-4c60-baa1-b3c8cabbcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's it like to write a million lines into a text file?\n",
    "filename = f\"{data}/text.txt\"\n",
    "with open(filename, \"wt\") as fh:\n",
    "    for i in range(1000000):\n",
    "        fh.write(f\"{i}\\n\")\n",
    "print(\"Done\")  # Fast!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73354b-fd5e-42eb-a423-852410934010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, how about a million lines into a Pandas DataFrame then parquet it?\n",
    "table = []\n",
    "for i in range(10**6):\n",
    "    table.append(i)\n",
    "df = pd.DataFrame(table, columns=[\"thousands\"])\n",
    "df.to_parquet(f\"{data}/morenotbutter.parquet\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d3dc6-3ea3-41fd-8775-44bf7b691dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is a million-line Pandas DataFrame stored in parquet format?\n",
    "filename = f\"{data}/morenotbutter.parquet\"\n",
    "bytesize = Path(filename).stat().st_size\n",
    "kilo = 1000\n",
    "print(f'The file \"{filename}\" is {bytesize:,} Bytes.')\n",
    "print(f\"Abbreviated to {bytesize / kilo:,.0f} Kilobytes.\")  # The :,0f formats\n",
    "print(f\"Or just {bytesize / kilo / kilo:.0f} Megs.\")\n",
    "print(\"Done\")\n",
    "# A million short lines is still several megs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb6c17-6082-4045-a7ae-0da13271a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing those file sizes seems useful.\n",
    "# Can we make that a reusable function?\n",
    "\n",
    "\n",
    "def get_size(afile):\n",
    "    filename = f\"{afile}\"\n",
    "    bytesize = Path(filename).stat().st_size\n",
    "    kilo = 1000\n",
    "    print(f'The file \"{filename}\" is {bytesize:,} Bytes.')\n",
    "    print(f\"Abbreviated to {bytesize / kilo:,.0f} Kilobytes.\")  # The :,0f formats\n",
    "    print(f\"Or just {bytesize / kilo / kilo:.0f} Megs.\")\n",
    "\n",
    "\n",
    "get_size(f\"{data}/morenotbutter.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7231e53-9553-486a-9ded-2129577e4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about with a real database? Let's use Python's SQLite.\n",
    "# What's it like to write 100,000 keys into a SQlite database?\n",
    "# Let's count down instead of up. Keys go up but count is down.\n",
    "# As you can see, having \"real\" database operations like unqiuness\n",
    "# enforced with Primary keys on Insert statements have a time cost.\n",
    "# Sometime's it's worth it, as with crawer data collection, but\n",
    "# in most cases, we pass on a real database in favor of parquet.\n",
    "\n",
    "filename = f\"{data}/database.db\"\n",
    "now = time()\n",
    "upto = 100000\n",
    "with sqldict(filename) as db:\n",
    "    for i in range(upto):\n",
    "        db[i] = None\n",
    "        if not i % 10000:\n",
    "            db.commit()\n",
    "            print(f\"{upto - i:,}...\", end=\" \")\n",
    "seconds = int(time() - now)\n",
    "get_size(filename)\n",
    "print(f\"\\nDone ({seconds} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa80cb-341a-4152-8800-57aa3c969fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count down from a billion by hundred-millions.\n",
    "# The point of running this is just to appreciate that big numbers are big.\n",
    "# It can take a minute to count down from a billion on your laptop.\n",
    "\n",
    "hundredmillion = 10**8\n",
    "billion = 10**9\n",
    "now = time()\n",
    "modulorow = 1\n",
    "print(\"Count down with me from a billion in Python:\")\n",
    "for i in range(billion):\n",
    "    if not i % hundredmillion:\n",
    "        glimpse = int(time() - now)\n",
    "        print(f\"{modulorow}: {billion - i:,} ({glimpse} sec)...\")\n",
    "        modulorow += 1\n",
    "seconds = int(time() - now)\n",
    "print(f\"Done ({seconds} seconds)\")  # Computers are fast but not that fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ec0c0-326c-4a88-81b5-a06cd2c0f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's a billion. Don't let it scare you. Hundreds of millions can be OK\n",
    "# if you use the right techniques to load, process and save data.\n",
    "# In this example we\n",
    "\n",
    "filename = f\"{data}/pickledump.pkl\"\n",
    "seen = set()\n",
    "ten_million = 10**6 * 10\n",
    "print(f\"{ten_million:,}\")\n",
    "\n",
    "for i in range(ten_million):\n",
    "    seen.add(i)\n",
    "print(f\"Made {len(seen):,} keys.\")\n",
    "\n",
    "# Dump pickled set to file\n",
    "with open(filename, \"wb\") as fh:\n",
    "    fh.write(dumps(seen))\n",
    "print(f'Saved \"{filename}\" to drive.')\n",
    "\n",
    "get_size(filename)\n",
    "\n",
    "# Load picled set out of file\"\n",
    "with open(filename, \"rb\") as fh:\n",
    "    seen = loads(fh.read())\n",
    "print(f\"Read native Python {type(seen)} back off of drive.\")\n",
    "print(f\"{ten_million:,} is no biggie using these techniques.\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d0b8c-28aa-4309-9df9-d1913dce321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're getting down to business. Cats!\n",
    "# We load a lot of packgees here so I have an easy entry-point later.\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from httpx import get\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from pickle import loads, dumps\n",
    "from imagehash import phash, whash\n",
    "from IPython.display import display\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "\n",
    "# Where we save cats and generate thumbs.\n",
    "# This also sets the stage for auto-classifiers.\n",
    "data = \"cats\"\n",
    "source = f\"{data}/source\"\n",
    "thumbs = f\"{data}/thumbs\"\n",
    "tagtable = Path(f\"{data}/tagtable.pkl\")\n",
    "by_types = [\"by_folder\", \"by_ham\", \"by_size\"]\n",
    "\n",
    "# Make those locatiosn if they don't exist.\n",
    "Path(data).mkdir(exist_ok=True)\n",
    "Path(source).mkdir(exist_ok=True)\n",
    "Path(thumbs).mkdir(exist_ok=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee9bdc-9d22-4510-be47-67779f75e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 30 cats that don't exist.\n",
    "\n",
    "# If you actually want to fetch 30 cats that don't exist again\n",
    "# then delete the contents of cats/source folder and re-run.\n",
    "# You can delete just a sinlge cat from source and watch it re-fill\n",
    "# except by doing so removes referenced data. Fetch more. Whatever.\n",
    "\n",
    "url = \"https://thiscatdoesnotexist.com/\"\n",
    "cats = 30\n",
    "for i in range(cats):\n",
    "    filename = f\"{source}/cat-{str(i).zfill(3)}.jpg\"\n",
    "    if not Path(filename).exists():\n",
    "        print(f\"{cats - i} Downloading: {filename}\")\n",
    "        response = get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(filename)\n",
    "        sleep(1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3a0e5-5c1b-42d2-8579-ed6d1c18b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate thumbnails for the source folder of cat images.\n",
    "# If you wish to see the thumbnails generate again, you have to\n",
    "# delete seencats.pkl and the contents of thumbs folder.\n",
    "\n",
    "size = 64\n",
    "\n",
    "# Load set of seen cats from pickle if exists.\n",
    "pickled_cats = f\"{data}/seencats.pkl\"\n",
    "if Path(pickled_cats).exists():\n",
    "    with open(pickled_cats, \"rb\") as fh:\n",
    "        seen = loads(fh.read())\n",
    "else:\n",
    "    seen = set()\n",
    "\n",
    "# Make thumbnails of cat pics.\n",
    "for cat in Path(source).glob(\"*.jpg\"):\n",
    "    img = Image.open(cat)\n",
    "    thumb = img.copy()\n",
    "    thumb.thumbnail((size, size))\n",
    "    awhash = whash(img, hash_size=8)\n",
    "    width, height = img.width, img.height\n",
    "    bands = \"\".join(img.getbands())\n",
    "    meta_data = {\n",
    "        \"filename\": cat.name,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"format\": img.format,\n",
    "        \"format_description\": img.format_description,\n",
    "        \"bands\": img.getbands(),\n",
    "        \"extremes\": img.getextrema(),\n",
    "        \"xmp\": img.getxmp(),\n",
    "    }\n",
    "    pi = PngInfo()\n",
    "    for meta in meta_data:\n",
    "        pi.add_text(meta, f\"{meta_data[meta]}\")\n",
    "    filename = f\"{width}x{height}_{awhash}_.png\"\n",
    "    if filename not in seen:\n",
    "        print(cat)\n",
    "        display(thumb)\n",
    "        seen.add(filename)\n",
    "        print(filename)\n",
    "        thumb.save(\n",
    "            f\"{thumbs}/{filename}\",\n",
    "            \"PNG\",\n",
    "            pnginfo=pi,\n",
    "            save_all=True,\n",
    "        )\n",
    "        print()\n",
    "with open(pickled_cats, \"wb\") as fh:\n",
    "    fh.write(dumps(seen))\n",
    "\n",
    "# Report size of file\n",
    "bytesize = Path(pickled_cats).stat().st_size\n",
    "print(f\"{pickled_cats} is {bytesize:,} Bytes\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341edde-e3d4-49fa-9b7c-72a70ff80328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_name(n):\n",
    "    sizes = {\n",
    "        4: \"Ten Thousand\",\n",
    "        5: \"Hundred Thousand\",\n",
    "        6: \"Million\",\n",
    "        9: \"Billion\",\n",
    "        12: \"Trillion\",\n",
    "        15: \"Quadrillion\",\n",
    "        18: \"Quintillion\",\n",
    "        21: \"Sextillion\",\n",
    "        24: \"Septillion\",\n",
    "        27: \"Octillion\",\n",
    "        30: \"Nonillion\",\n",
    "        33: \"Decillion\",\n",
    "        36: \"Undecillion\",\n",
    "        39: \"Duodecillion\",\n",
    "        42: \"Tredecillion\",\n",
    "        45: \"Quattuordecillion\",\n",
    "        48: \"Quindecillion\",\n",
    "        51: \"Sexdecillion\",\n",
    "        54: \"Septendecillion\",\n",
    "        57: \"Octodecillion\",\n",
    "        60: \"Novemdecillion\",\n",
    "        63: \"Vigintillion\",\n",
    "    }\n",
    "    exponent = len(str(n)) - 1\n",
    "    exponent -= exponent % 3\n",
    "    size = sizes.get(exponent, \"extremely large\")\n",
    "    return size\n",
    "\n",
    "\n",
    "# Notice how some cats are more hexed than others.\n",
    "print(\"How unique can a 16-digit hexidecimal number really be?\")\n",
    "print()\n",
    "print(\"Filename_extract converted_2hex decimal big_number_name...\")\n",
    "for cat in seen:\n",
    "    parts = cat.split(\"_\")\n",
    "    whash = parts[1]\n",
    "    ahex = hex(int(whash, 16))\n",
    "    adec = int(ahex, 16)\n",
    "    word = size_name(adec)\n",
    "\n",
    "    print(whash, ahex, f\"{adec:,}\", word)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456ebf3-2a33-40d9-873f-7c64acf561c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import scandir\n",
    "\n",
    "\n",
    "def build_cdict(path):\n",
    "    global sort_choice, by_types, cdict, seen, seensizes, tags\n",
    "    for entry in scandir(path):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            try:\n",
    "                build_cdict(entry.path)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                found = entry.stat(follow_symlinks=False)\n",
    "            except:\n",
    "                continue\n",
    "            name, path = entry.name, entry.path\n",
    "            seen.add(name)\n",
    "            path = path.split(\"/\")\n",
    "            parts = name.split(\"_\")\n",
    "            size = parts[0]\n",
    "            cdict[name] = \"/\".join(path[:-1])\n",
    "            if sort_choice == \"by_folder\":\n",
    "                classifications = path[2:-1]\n",
    "                classifications = [\n",
    "                    x\n",
    "                    for x in classifications\n",
    "                    if not x.isnumeric() and x not in by_types\n",
    "                ]\n",
    "            elif sort_choice == \"by_size\":\n",
    "                classifications = [size]\n",
    "            else:\n",
    "                classifications = []\n",
    "            if classifications:\n",
    "                tuples = [(name, tag) for tag in classifications]\n",
    "                [tags.add(atuple) for atuple in tuples]\n",
    "    return cdict\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043cc4b-57be-4856-baf1-b32ca076b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate minimum hamming distance, seen sizes and histo distances.\n",
    "\n",
    "import matplotlib.pyplot as plt  # To display data (graphs)\n",
    "\n",
    "# Update cdict with latest file locations\n",
    "cdict = {}\n",
    "tags = set()\n",
    "seen = set()\n",
    "seensizes = set()\n",
    "ham_goes = {}\n",
    "hist_goes = {}\n",
    "\n",
    "# First we auto-classify by width x height formats.\n",
    "sort_choice = \"\"\n",
    "cdict = build_cdict(thumbs)\n",
    "hamdiffs = Counter()\n",
    "cat_pairs = set()\n",
    "hdict = {}\n",
    "for cat1 in cdict:\n",
    "    parts1 = cat1.split(\"_\")\n",
    "    file_path = f\"{cdict[cat1]}/{cat1}\"\n",
    "    img = Image.open(file_path)\n",
    "    hdict[cat1] = img.histogram()\n",
    "    washcat1 = parts1[1]\n",
    "    for cat2 in cdict:\n",
    "        parts2 = cat2.split(\"_\")\n",
    "        washcat2 = parts2[1]\n",
    "        int1, int2 = [int(x, 16) for x in (washcat1, washcat2)]\n",
    "        if int1 != int2:\n",
    "            diff = bin(int1 ^ int2).count(\"1\")\n",
    "            append_list = [int(diff)]\n",
    "            catpairdiff = tuple(sorted([washcat1, washcat2]) + append_list)\n",
    "            hamdiffs[diff] += 1\n",
    "            cat_pairs.add(catpairdiff)\n",
    "sorted_dict = dict(sorted(hamdiffs.items(), key=lambda item: item[0], reverse=False))\n",
    "plt.bar(hamdiffs.keys(), hamdiffs.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Hamming Distance Groups\")\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(cat_pairs, columns=[\"cat1\", \"cat2\", \"ham\"])\n",
    "min_hams = set()\n",
    "for cat in df.groupby(\"cat1\"):\n",
    "    name, dfg = cat\n",
    "    min_ham = dfg.ham.min()\n",
    "    min_ham = str(min_ham).zfill(2)\n",
    "    min_hams.add(min_ham)\n",
    "    ham_goes[name] = min_ham\n",
    "for whash in {x.split(\"_\")[1] for x in cdict} - ham_goes.keys():\n",
    "    ham_goes[whash] = \"00\"\n",
    "print(\"minimum hams:\", min_hams)\n",
    "print(\"total minimums:\", len(min_hams))\n",
    "print(len(ham_goes))\n",
    "\n",
    "sort_choice = \"by_ham\"\n",
    "cdict = build_cdict(f\"{data}/thumbs\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a34223-6b0d-4c68-97f7-42d84e632df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hist_goes grouping dict.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "sort_choice = \"\"\n",
    "cdict = build_cdict(thumbs)\n",
    "intersections = []\n",
    "image_paths = []\n",
    "\n",
    "\n",
    "for file in cdict:\n",
    "    path = cdict[file]\n",
    "    filepath = f\"{path}/{file}\"\n",
    "    img = Image.open(filepath)\n",
    "    hist = img.histogram()\n",
    "    intersections.append(hist)\n",
    "    image_paths.append(file)\n",
    "\n",
    "table = []\n",
    "for r in range(int(len(intersections) / 3), 2, -1):\n",
    "    kmeans = KMeans(n_clusters=r, n_init=\"auto\").fit(intersections)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    clusters = {}\n",
    "    for i, assignment in enumerate(cluster_assignments):\n",
    "        if assignment not in clusters:\n",
    "            clusters[assignment] = []\n",
    "        clusters[assignment].append(image_paths[i])\n",
    "    counts = [(len(clusters[x])) for x in clusters]\n",
    "    print(counts)\n",
    "    if len([x for x in counts if x == 1]) <= 2:\n",
    "        n = len(counts)\n",
    "        break\n",
    "\n",
    "for i, assignment in enumerate(cluster_assignments):\n",
    "    if assignment not in clusters:\n",
    "        clusters[assignment] = []\n",
    "    clusters[assignment].append(image_paths[i])\n",
    "hist_goes = {}\n",
    "for label in clusters:\n",
    "    cluster = clusters[label]\n",
    "    for file in cluster:\n",
    "        hist_goes[file] = str(label).zfill(3)\n",
    "\n",
    "plt.bar(clusters.keys(), counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Histogram Clusters\")\n",
    "plt.ylabel(\"Matches in Group\")\n",
    "plt.xlabel(\"Histogram Intersection Groups\")\n",
    "plt.show()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54c906-a001-41e0-bd65-c5fc903b7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort cats into minimum hamming-distance folders\n",
    "def sort_it(by=\"\"):\n",
    "    for file in cdict:\n",
    "        from_folder = cdict[file]\n",
    "        parts = file.split(\"_\")\n",
    "        size, whash = parts[:2]\n",
    "\n",
    "        by_dict = {\n",
    "            \"by_hist\": hist_goes[file],\n",
    "            \"by_ham\": ham_goes[whash],\n",
    "            \"by_size\": size,\n",
    "            \"\": \"\",\n",
    "        }\n",
    "        if sort_choice == \"by_folder\":\n",
    "            to_folder = Path(file)\n",
    "        else:\n",
    "            try:\n",
    "                to_folder = Path(f\"{data}/thumbs/{by}/{by_dict[by]}\")\n",
    "            except:\n",
    "                continue\n",
    "        if not to_folder.is_dir():\n",
    "            Path(to_folder).mkdir(parents=True, exist_ok=True)\n",
    "        full_path = f\"{from_folder}/{file}\"\n",
    "        dest_file = Path(f\"{to_folder}/{file}\")\n",
    "        if not dest_file.is_file():\n",
    "            dest = shutil.move(full_path, to_folder)\n",
    "            cdict[file] = to_folder\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1d18e-9963-442c-823c-542ccf49f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort thumbnails by similar color usage.\n",
    "sort_choice = \"by_hist\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it(sort_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba930900-8c14-4117-a16a-4e78513bb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6f59c-27d0-4fed-bc58-3a7434401d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort thumbnails by size.\n",
    "sort_choice = \"by_size\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it(sort_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f3b4f-1d6c-4e82-9be5-27441445144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort thumbnails by minimum hamming distances.\n",
    "sort_choice = \"by_ham\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it(sort_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba15c8-8500-4596-8336-f7f2d919a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all thumbnails back to top-level.\n",
    "sort_choice = \"\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae93c1-eb9e-432f-9055-341c4c635ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drag things into folders to tag them.\n",
    "\n",
    "sort_choice = \"by_folder\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it(sort_choice)\n",
    "if not tagtable.exists():\n",
    "    with open(tagtable, \"wb\") as fh:\n",
    "        fh.write(dumps(tags))\n",
    "else:\n",
    "    with open(tagtable, \"rb\") as fh:\n",
    "        existig_tags = loads(fh.read())\n",
    "        [existig_tags.add(x) for x in tags]\n",
    "    with open(tagtable, \"wb\") as fh:\n",
    "        fh.write(dumps(existig_tags))\n",
    "print(\"Done\")\n",
    "\n",
    "# We can use DataFrames to do our MatplotLibs.\n",
    "df = pd.DataFrame(existig_tags, columns=[\"file\", \"tag\"])\n",
    "df.groupby(\"tag\").count().plot(kind=\"bar\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a23f2d-d230-4707-ac91-0e80a889bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, the meta data is stplotin the PNG thumnails.\n",
    "for i, cat in enumerate(cdict):\n",
    "    file = f\"{cdict[cat]}/{cat}\"\n",
    "    print(file)\n",
    "    img = Image.open(file)\n",
    "    meta = img.text\n",
    "    for key in meta:\n",
    "        print(f\"{key}: {meta[key]}\")\n",
    "    print()\n",
    "    if i >= 2:\n",
    "        break  # Seen enough proof?\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883ec51-e9a4-4a0f-9afa-8c3117f56775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d7101-10b8-4b38-98af-1573efe35c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
