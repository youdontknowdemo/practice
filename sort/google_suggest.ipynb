{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79092a-13f4-4e89-b4de-a77058d6ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe122c7-a744-4d47-9b5b-a099a75e6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b457e6-b10c-4d5a-90aa-0fd8733e9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try values like what, how\n",
    "original_query = \"how\"\n",
    "\n",
    "namespace = \"suggest\"\n",
    "Path(namespace).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "base_url = \"http://suggestqueries.google.com/complete/search?client=firefox&&q=\"\n",
    "url = f\"{base_url}{original_query}\"\n",
    "response = requests.get(url)\n",
    "table = []\n",
    "for i, suggestion in enumerate(response.json()[1]):\n",
    "    row = (original_query, i + 1, suggestion)\n",
    "    table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d299e1-c70c-4b81-adb6-c048a7ceed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_words = \"\"\"about\n",
    "above\n",
    "after\n",
    "again\n",
    "against\n",
    "all\n",
    "am\n",
    "an\n",
    "and\n",
    "any\n",
    "are\n",
    "aren't\n",
    "as\n",
    "at\n",
    "be\n",
    "because\n",
    "been\n",
    "before\n",
    "being\n",
    "below\n",
    "between\n",
    "both\n",
    "but\n",
    "by\n",
    "can\n",
    "couldn't\n",
    "did\n",
    "didn't\n",
    "do\n",
    "does\n",
    "doesn't\n",
    "doing\n",
    "don't\n",
    "down\n",
    "during\n",
    "each\n",
    "few\n",
    "for\n",
    "from\n",
    "further\n",
    "had\n",
    "hadn't\n",
    "has\n",
    "hasn't\n",
    "have\n",
    "haven't\n",
    "having\n",
    "he\n",
    "her\n",
    "here\n",
    "hers\n",
    "herself\n",
    "him\n",
    "himself\n",
    "his\n",
    "how\n",
    "if\n",
    "in\n",
    "into\n",
    "is\n",
    "isn't\n",
    "it\n",
    "it's\n",
    "its\n",
    "itself\n",
    "just\n",
    "me\n",
    "mightn't\n",
    "more\n",
    "most\n",
    "mustn't\n",
    "my\n",
    "myself\n",
    "needn't\n",
    "no\n",
    "nor\n",
    "not\n",
    "now\n",
    "of\n",
    "off\n",
    "on\n",
    "once\n",
    "only\n",
    "or\n",
    "other\n",
    "our\n",
    "ours\n",
    "ourselves\n",
    "out\n",
    "over\n",
    "own\n",
    "re\n",
    "same\n",
    "shan't\n",
    "she\n",
    "she's\n",
    "should\n",
    "should've\n",
    "shouldn't\n",
    "so\n",
    "some\n",
    "such\n",
    "than\n",
    "that\n",
    "that'll\n",
    "the\n",
    "their\n",
    "theirs\n",
    "them\n",
    "themselves\n",
    "then\n",
    "there\n",
    "these\n",
    "they\n",
    "this\n",
    "those\n",
    "through\n",
    "to\n",
    "too\n",
    "under\n",
    "until\n",
    "up\n",
    "very\n",
    "was\n",
    "wasn't\n",
    "we\n",
    "were\n",
    "weren't\n",
    "what\n",
    "when\n",
    "where\n",
    "which\n",
    "while\n",
    "who\n",
    "whom\n",
    "why\n",
    "will\n",
    "with\n",
    "won't\n",
    "wouldn't\n",
    "you\n",
    "you'd\n",
    "you'll\n",
    "you're\n",
    "you've\n",
    "your\n",
    "yours\n",
    "yourself\n",
    "yourselves\"\"\".split(\n",
    "    \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374581e-cbda-4c4e-97d6-dcdd3c1ba38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_letters = f\" {string.ascii_lowercase}\"\n",
    "len_letters = len(lowercase_letters)\n",
    "for letter in lowercase_letters:\n",
    "    query = f\"{original_query} {letter}\"\n",
    "    url = f\"{base_url}{query}\"\n",
    "    response = requests.get(url)\n",
    "    for suggestion in response.json()[1]:\n",
    "        row = (query, i + 1, suggestion)\n",
    "        table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba209b-c814-4aa0-830b-2182a84c2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in probe_words:\n",
    "    query = f\"{original_query} {word} \"\n",
    "    url = f\"{base_url}{query}\"\n",
    "    response = requests.get(url)\n",
    "    for i, suggestion in enumerate(response.json()[1]):\n",
    "        row = (query, i + 1, suggestion)\n",
    "        table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36863d-bcbd-4abe-8f69-0ba47075de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(table, columns=[\"seed\", \"position\", \"suggestion\"])\n",
    "filename = f\"suggestions-{original_query.replace(' ', '_')}.csv\"\n",
    "df.to_csv(f\"{namespace}/{filename}\", index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f5962-3ee1-47b9-8869-8252876b13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter()\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "inverter = {1: 10, 2: 9, 3: 8, 4: 7, 5: 6, 6: 5, 7: 4, 8: 3, 9: 2, 10: 1, 11: 1}\n",
    "\n",
    "\n",
    "def sort_counter_descending(counter):\n",
    "    return sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def cluster_keywords(keywords, num_clusters):\n",
    "    # Convert the keywords to a TF-IDF matrix\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(keywords)\n",
    "\n",
    "    # Perform k-means clustering on the TF-IDF matrix\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # Get the cluster assignments for each keyword\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    return cluster_assignments\n",
    "\n",
    "\n",
    "lowr = lambda x: x.lower()\n",
    "alfa = lambda x: re.sub(r\"[^a-zA-Z\\s]\", \"\", x)\n",
    "sspc = lambda x: re.sub(\" +\", \" \", x)\n",
    "flat = lambda x: \" \".join(x)\n",
    "tkns = lambda x: word_tokenize(x)\n",
    "nstp = lambda x: flat([y for y in tkns(lowr(x)) if y not in stop_words])\n",
    "\n",
    "# Establish all counters\n",
    "for kw in table:\n",
    "    c[kw[2]] += 1\n",
    "\n",
    "root_hist = Counter()\n",
    "for kw in table:\n",
    "    query, position, suggestion = kw\n",
    "\n",
    "    # Give suggestions from seed term a boost.\n",
    "    if query == original_query:\n",
    "        c[suggestion] += 5\n",
    "\n",
    "    # Boost each keyword based on its suggestion position.\n",
    "    c[suggestion] += inverter[position]\n",
    "\n",
    "    # Boost when highly specific yet still suggested\n",
    "    delta = suggestion.replace(original_query, \"\").strip()\n",
    "    delta_num_words = len(delta.split())\n",
    "    if delta_num_words > 1:\n",
    "        c[suggestion] += (delta_num_words - 1) * 3\n",
    "\n",
    "    # Create histogram of cleaned deltas\n",
    "    root = nstp(delta)\n",
    "    if root:\n",
    "        root_hist[root] += 1\n",
    "\n",
    "for kw in table:\n",
    "    query, position, suggestion = kw\n",
    "    delta = suggestion.replace(original_query, \"\").strip()\n",
    "    root = nstp(delta)\n",
    "    c[suggestion] += root_hist[root] * 2\n",
    "\n",
    "# sort_counter_descending(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760d144-901b-4c68-9c75-f646a64343fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example list of keywords\n",
    "keywords = list(root_hist.keys())\n",
    "num_keywords = len(keywords)\n",
    "\n",
    "# Cluster the keywords into 3 clusters\n",
    "print(\"Finding least number of clusters that produce only 2 empty groups.\")\n",
    "for i in range(2, int(num_keywords / 2)):\n",
    "    num_clusters = int(num_keywords / i)\n",
    "    print(f\"Keywords: {num_keywords}\")\n",
    "    print(f\"Number of Clusters: {num_clusters}\")\n",
    "    cluster_assignments = cluster_keywords(keywords, num_clusters)\n",
    "    # print(cluster_assignments)\n",
    "    num_zeros = np.count_nonzero(cluster_assignments == 0)\n",
    "    max_group = np.amax(cluster_assignments)\n",
    "    print(f\"Max: {max_group}\")\n",
    "    print(f\"Number of zeros: {num_zeros}\")\n",
    "    if num_zeros >= 3:\n",
    "        denominator = i - 1\n",
    "        print(f\"Denominator to use: {int(denominator)}\")\n",
    "        break\n",
    "num_clusters = int(num_keywords / denominator)\n",
    "cluster_assignments = cluster_keywords(keywords, num_clusters)\n",
    "print(cluster_assignments)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b917f-be1c-4627-8f73-491a27b194d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mab beloingings between keywords and thier clusters\n",
    "cluster_dict = {}\n",
    "for i, keyword in enumerate(keywords):\n",
    "    cluster_dict[keyword] = cluster_assignments[i]\n",
    "# cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35691546-e4c8-4e7c-ac72-c482e5dbb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce keyword groups using numbers as the group names.\n",
    "\n",
    "sublist_dict = {}\n",
    "for i, keyword in enumerate(keywords):\n",
    "    group_number = cluster_assignments[i]\n",
    "    if group_number in sublist_dict:\n",
    "        # Encountered group number before. Append new keyword.\n",
    "        sublist_dict[group_number].append(keyword)\n",
    "    else:\n",
    "        # First time group number is encountered make 1-val list.\n",
    "        sublist_dict[group_number] = [keyword]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac6066a-a036-42d1-8d4c-8efff72ac11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a counter of 2-word combos\n",
    "def common2(keywords):\n",
    "    # Split each keyword into a list of words\n",
    "    words_list = [keyword.split() for keyword in keywords]\n",
    "\n",
    "    # Create a list of all 2-word combinations\n",
    "    two_word_combinations = []\n",
    "    for words in words_list:\n",
    "        for i in range(len(words) - 1):\n",
    "            two_word_combinations.append(f\"{words[i]} {words[i + 1]}\")\n",
    "\n",
    "    # Count the occurrences of each 2-word combination\n",
    "    two_word_counter = Counter(two_word_combinations)\n",
    "\n",
    "    return two_word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb7a11-a411-4148-9cea-b0f0c63c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This maps a most frequent 2-word combo to replace the numbered group names.\n",
    "named_sublist_dict = {}\n",
    "p = False\n",
    "for group_number in sublist_dict:\n",
    "    keywords = sublist_dict[group_number]\n",
    "    best2s = common2(keywords)\n",
    "    if p:\n",
    "        print(f\"Keywords: {keywords}\")\n",
    "        print(f\"The best 2-word combos: {best2s}\")\n",
    "    if group_number not in named_sublist_dict:\n",
    "        for candidate in best2s:\n",
    "            if candidate not in named_sublist_dict:\n",
    "                named_sublist_dict[group_number] = candidate\n",
    "                if p:\n",
    "                    print(f'\"{candidate}\" used for group number {group_number}.')\n",
    "                break\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524372f3-55be-4e87-867a-6cdbb20386be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the top 2-word combo as the name for each keyword group.\n",
    "named_clusters = [\n",
    "    (named_sublist_dict[x], sublist_dict[x])\n",
    "    for x in sublist_dict\n",
    "    if x in named_sublist_dict\n",
    "]\n",
    "dict_o_sets = dict([(x[0], set([x[0]] + x[1])) for x in named_clusters])\n",
    "\n",
    "word_values = dict(\n",
    "    [\n",
    "        (x[0].replace(original_query, \"\").strip(), x[1])\n",
    "        for x in sort_counter_descending(c)\n",
    "    ]\n",
    ")\n",
    "\n",
    "group_values = [\n",
    "    (x, [word_values[y] for y in dict_o_sets[x] if y in word_values])\n",
    "    for x in dict_o_sets\n",
    "]\n",
    "group_scores = [(x[0], round(sum(x[1]) / len(x[1]), 2)) for x in group_values if x[1]]\n",
    "most_valuable_groups = dict(sorted(group_scores, key=lambda x: x[1], reverse=True))\n",
    "\n",
    "table = []\n",
    "for group_name in most_valuable_groups:\n",
    "    score = most_valuable_groups[group_name]\n",
    "    for keyword in dict_o_sets[group_name]:\n",
    "        row = (group_name, keyword, score)\n",
    "        table.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(table, columns=[\"Group Name\", \"Keyword\", \"Group Score\"])\n",
    "\n",
    "cluster_csv = f\"cluster-{original_query.replace(' ', '_')}.csv\"\n",
    "df2.to_csv(f\"{namespace}/{cluster_csv}\", index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d715a7-48d9-48e5-8d0f-a14f2af8daa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbf58d-43be-4322-92cc-6e8d8750a213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
